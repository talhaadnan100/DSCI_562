---
title: "Horeshoe crab case study: models under various assumptions"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

Let's continue working with the horseshoe crab data from last time. Today, we'll fit three models under different assumptions, evaluating their usefulness.

```{r}
suppressPackageStartupMessages(library(tidyverse))
crab <- read_table("https://newonlinecourses.science.psu.edu/stat504/sites/onlinecourses.science.psu.edu.stat504/files/lesson07/crab/index.txt", col_names = FALSE) %>% 
  select(-1) %>% 
  setNames(c("colour","spine","width","weight","n_male")) %>% 
  mutate(colour = factor(colour),
         spine  = factor(spine))
head(crab)
```

Case study: how do features of nesting female horseshoe crabs influence the number of males found nearby? Let's see how carapace width influences the mean number of males nearby.

```{r, fig.width=6, fig.height=3}
p <- ggplot(crab, aes(width, n_male)) + 
  geom_point(alpha=0.25) +
  labs(x = "Carapace Width", 
       y = "No. males\nnearby") +
  theme_bw() +
  theme(axis.title.y = element_text(angle=0, vjust=0.5))
plotly::ggplotly(p)
```

Data source: [H. Jane Brockmann's 1996 paper](https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1439-0310.1996.tb01099.x); found online [here](https://newonlinecourses.science.psu.edu/stat504/sites/onlinecourses.science.psu.edu.stat504/files/lesson07/crab/index.txt); another regression demo with this data is found [here](https://newonlinecourses.science.psu.edu/stat504/node/169/).


## Approach 1: Estimate regression curve / model function locally

Optimize the loess fit by eye. Just modify span, to keep things simple.

<<<<<<< HEAD
```{r, fig.width=6, fig.height=4}
grid <- seq(min(crab$width), max(crab$width), length.out=1000)
grid_df <- tibble(width = grid)
model1 <- loess(n_male ~ width, data=crab, degree = 2, span = 0.5)
=======
```{r, fig.width=4, fig.height=3}
grid <- seq(min(crab$width), max(crab$width), length.out=100)
grid_df <- tibble(width = grid)
model1 <- loess(n_male ~ width, data=crab, degree=2, span=0.5)
>>>>>>> upstream/master
grid_df %>% 
  mutate(., yhat = predict(model1, .)) %>% 
  ggplot(aes(width, yhat)) +
  geom_line(colour="blue") +
  geom_point(data=crab, mapping=aes(width, n_male), alpha=0.25)
```

What's the error of this model? Training error is fine.

```{r}
resid1 <- crab$n_male - predict(model1)
(error1 <- mean(resid1^2))
```

How well does this model answer our original question?

**Comment:** It is a good predictive model, but not an excellent interpretive model.

## Approach 2: Linear Regression

### Fit a linear regression model

Fit a linear regression model.

```{r, fig.width=4, fig.height=3}
model2 <- lm(n_male ~ width, data=crab)
ggplot(crab, aes(width, n_male)) +
    geom_point(alpha=0.25) +
    geom_smooth(method="lm", se=FALSE)
```

Error:

```{r}
resid2 <- crab$n_male - predict(model2)
(error2 <- mean(resid2^2))
```


How well does this model answer our original question? Do you see a potential problem with this model? Are any assumptions of linear regression not true? Brainstorm ideas for how to deal with the problems.

## New approaches

Let's talk about an alternative approach called _Generalized Linear Models_ (GLM). Topics:

- Appropriate transformation: on Y? On E(Y|X)? Link function definitions.
- Interpretation of parameters under log and logit links.
- Fitting the model function: Is LS "valid"? Can we do better? 
    - The two types of parametric assumptions, their risk, and their value.
    - Review of MLE?
    - Nomenclature: Poisson regression; Binomial/Bernoulli/Logistic regression.

## Approach 3: Link Function

Fit a GLM. Plot using `ggplot2`, making use of the `method.args` argument of `geom_smooth()`.

<<<<<<< HEAD
```{r}
model3 <- glm(n_male ~ width, data=crab, family = poisson)
ggplot(crab, aes(width, n_male)) +
    geom_point(alpha=0.25) +
    geom_smooth(method="glm", se=FALSE, method.args = )
resid3 <- crab$n_male - predict(model3, type='response')
=======
```{r, fig.width=4, fig.height=3}
model3 <- glm(n_male ~ width, data=crab, family=poisson)
ggplot(crab, aes(width, n_male)) +
    geom_point(alpha=0.25) +
    geom_smooth(method="glm", se=FALSE, method.args=list(family=poisson))
```

Error:

```{r}
resid3 <- crab$n_male - predict(model3, type="response")
>>>>>>> upstream/master
(error3 <- mean(resid3^2))
```


## A note on error comparison

Here are the errors of the above three models:

```{r}
tribble(
	~ method, ~ MSE,
	"local", error1,
	"linear", error2,
	"GLM", error3
)
```

This suggests that the model function from the local method fits the data best, and that the exponential model function (GLM) fits the data poorest. This means that for _prediction_, the local model is best. 

If our interest is interpretation, error measurements are less important. Here, the linear model is probably fine, since the model function does not drop below zero within the span of the data. Since it also fits better than the GLM, there's probably no harm in choosing it for interpretation -- unless you particularly care about the relationship for small horseshoe crabs!

## Approach 4: Scientifically motivated model function?

There's probably none here, but if there was, what then?
