---
title: "Horeshoe crab case study: models under various assumptions"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

Let's continue working with the horseshoe crab data from last time. Today, we'll fit three models under different assumptions, evaluating their usefulness.

```{r}
suppressPackageStartupMessages(library(tidyverse))
crab <- read_table("https://newonlinecourses.science.psu.edu/stat504/sites/onlinecourses.science.psu.edu.stat504/files/lesson07/crab/index.txt", col_names = FALSE) %>% 
  select(-1) %>% 
  setNames(c("colour","spine","width","weight","n_male")) %>% 
  mutate(colour = factor(colour),
         spine  = factor(spine))
knitr::kable(head(crab))
```

Case study: how do features of nesting female horseshoe crabs influence the number of males found nearby? Let's see how carapace width influences the mean number of males nearby.

```{r, fig.width=6, fig.height=3}
p <- ggplot(crab, aes(width, n_male)) + 
  geom_point(alpha=0.25) +
  labs(x = "Carapace Width", 
       y = "No. males\nnearby") +
  theme_bw() +
  theme(axis.title.y = element_text(angle=0, vjust=0.5))
plotly::ggplotly(p)
```

Data source: [H. Jane Brockmann's 1996 paper](https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1439-0310.1996.tb01099.x); found online [here](https://newonlinecourses.science.psu.edu/stat504/sites/onlinecourses.science.psu.edu.stat504/files/lesson07/crab/index.txt); another regression demo with this data is found [here](https://newonlinecourses.science.psu.edu/stat504/node/169/).


## Approach 1: Estimate regression curve / model function locally

Optimize the loess fit by eye. Just modify span, to keep things simple.

```{r, fig.width=6, fig.height=4}
grid <- seq(min(crab$width), max(crab$width), length.out=1000)
grid_df <- tibble(width = grid)
model1 <- loess(n_male ~ width, data=crab, degree = 2, span = 0.5)
grid_df %>% 
  mutate(., yhat = predict(model1, .)) %>% 
  ggplot(aes(width, yhat)) +
  geom_line(colour="blue") +
  geom_point(data=crab, mapping=aes(width, n_male), alpha=0.25)
```

What's the error of this model? Training error is fine.

```{r}
resid1 <- crab$n_male - predict(model1)
(error1 <- mean(resid1^2))
```

How well does this model answer our original question?

**Comment:** It is a good predictive model, but not an excellent interpretive model.

## Approach 2: Linear Regression

### Fit a linear regression model

Fit a linear regression model. What's the error?

```{r}
model2 <- lm(n_male ~ width, data=crab)
ggplot(crab, aes(width, n_male)) +
    geom_point(alpha=0.25) +
    geom_smooth(method="lm", se=FALSE)
resid2 <- crab$n_male - predict(model2)
(error2 <- mean(resid2^2))
```

How well does this model answer our original question? Do you see a potential problem with this model? Are any assumptions of linear regression not true? Brainstorm ideas for how to deal with the problems.

## New approaches

Let's talk about an alternative approach called _Generalized Linear Models_ (GLM). Topics:

- Appropriate transformation: on Y? On E(Y|X)? Link function definitions.
- Interpretation of parameters under log and logit links.
- Fitting the model function: Is LS "valid"? Can we do better? 
    - The two types of parametric assumptions, their risk, and their value.
    - Review of MLE?
    - Nomenclature: Poisson regression; Binomial/Bernoulli/Logistic regression.

## Approach 3: Link Function

Fit a GLM. Plot using `ggplot2`, making use of the `method.args` argument of `geom_smooth()`. What's the error?

```{r}
model3 <- glm(n_male ~ width, data=crab, family = poisson)
ggplot(crab, aes(width, n_male)) +
    geom_point(alpha=0.25) +
    geom_smooth(method="glm", se=FALSE, method.args = )
resid3 <- crab$n_male - predict(model3, type='response')
(error3 <- mean(resid3^2))
```

Bonus: generate some data under the fitted model. How does it compare?

## Approach 4: Scientifically motivated model function?

There's probably none here, but if there was, what then?
