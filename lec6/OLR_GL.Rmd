---
title: "OLR_guestlecture"
author: "Sunny"
date: "March 5, 2019"
output:
  pdf_document: default
  html_document: default
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls(all=TRUE))
require(tidyverse)
require(MASS)
require(broom)
require(lmtest)
require(foreign)
require(reshape2)
```


## Research Question                                                                                         
What's the reason(s) that influence the probability of a student applying to a graduate school?           

H1: The higher the GPA, the more likely that a student apply to graduate school                           
H2: If one of the parents has a graduate degree, more likely the student want to apply to graduate school

Take a look at the data, we want to know how the possibility of apply to graduate school influenced by gpa and pared. We have 400 observations.

- apply (ordinal)unlikely, somewhatlikely, unlikely
- pared (binary) whether at least one parent has a graduate degree
- gpa (continuous) grade point average

```{r, results = 'hide'}
score <- read.dta("https://stats.idre.ucla.edu/stat/data/ologit.dta") %>%
  as_data_frame() %>%
  dplyr::select(apply, pared, gpa) %>%
  mutate(apply=factor(apply, ordered=T),
         pared=factor(pared))

```

```{r}
score
```


## Data visualization/exploration
Here we want to have a general idea about how the data look like, so that we can have a sense that whether our hypothesis make sense or not. But remember, this exploratory analysis can not provide any "statistical conclusion", it is simply describing the data. We will need to fit models and do the tests before writing any conclusion. 

- Relationship between apply and pared? In the same application category, "very likely" has the highest percentage of having a parent who has graduate degree 

```{r}
table <- ftable(xtabs(~apply+pared, data=score)) %>%
  as.data.frame.matrix() 
rownames(table) <- c("unlikely", "somewhat likely", "very likely")
colnames(table) <- c("pared=0", "pared=1")
table$percent <- table[,2]/(table[,2]+table[,1])
table
```


- Relationship between apply and gpa? -> wow, higher gpa seems to assoiated with higher probability in applying

```{r}
value <- score %>%
  group_by(apply) %>%
  summarize(mean(gpa))
value
```

```{r, echo=FALSE}
scorep <- score %>%
  ggplot(aes(x=apply, y=gpa))+
    geom_boxplot(size=.75)+
    geom_jitter(alpha=.1, height=.2)+
    facet_grid(.~score$pared)+
    theme(axis.text.x=element_text(angle=45, hjust=1, vjust=1))+
    coord_flip()
scorep  
```


## Model formulation

##### Option 1: OLS regression (violation of assumption that the response needs to be interval outcome)

```{r}
lm.M1 <- score %>%
  mutate(apply.c=as.numeric(score$apply)) %>%
  lm(apply.c~pared+gpa, data=.)
```

Let's take a look at the goodness of fit (ANOVA table).

```{r}
anova(lm.M1) # get the Anova table for the model, including the F test
```

In the ANOVA table, our predictors (pared and gpa) are all significant in the t-test. Also, the model F-test is significant. Those mean our linear regression is very nice? No, because "the tests are only reliable when the assumptions of linear regression were met". So, before being too happy about the results, let's take a look at whether the assumptions were met or not (see below).

```{r, echo=FALSE}
score <- score %>%
  mutate(apply.c=as.numeric(score$apply),
         yhat.lm.M1=fitted(lm.M1), # the estimated y values
         resid.lm.M1=resid(lm.M1)) # the errors
par(mfrow=c(2,2),mai=c(0.6,0.6,0.6,0.6),cex=0.7)
plot(score$yhat.lm.M1,score$resid.lm.M1, main="lm M1, Residual Plot",
     xlab="yhat", ylab="residual")
plot(score$apply.c,score$yhat.lm.M1, main="lm M1, Fitted line plot",
     ylab="yhat", xlab="apply")
qqnorm(score$resid.lm.M1, main="lm M1, Normality plot")
hist(score$resid.lm.M1, breaks =8 , density=10,col="green", border="black",
     main="lm M1, Error Distribution") 
par(mfrow=c(1,1),mai=c(1.0,1.0,1.0,1.0),cex=1.0)
```

- Normality plot: Normality assumption is not met as the points are not in a straight line. The estimated coefficients are biased.
- Residual plot: Equal variance assumption is not met as there is a shape in the residual plot. The estimated variance of the coefficients are biased.

Combined together, all the coefficient t-tests, and model F-test are biased (not correct). (Oops!) But we can still take a look how the fitted line looks like in our data. 

```{r}
lm.M1.plot <- score %>%
  ggplot(aes(y=apply.c, x=gpa))+
    geom_jitter(alpha=.2, height=.2) +
    geom_line(aes(x=gpa, y=yhat.lm.M1))+
    facet_grid(.~score$pared)
lm.M1.plot
```

##### Option 2: Classifier (loss the information contained in the ordering)

```{r}
#Give it a try! :D 
```


##### Option 3: Ordinal logistic regression (Sounds great!) 
```{r, echo=FALSE, results = 'hide'}
olr.M0 <- polr(apply~1, data=score)         #Null model, no predictors
olr.M1 <- polr(apply~pared*gpa, data=score) #Full model, two predictors with interaction.
olr.M2 <- polr(apply~pared+gpa, data=score) #Reduced model, without interaction.
olr.M3 <- polr(apply~pared, data=score)     #Reduced model, with only pared.
olr.M4 <- polr(apply~gpa, data=score)       #Reduced model, with only gpa.

#Are gpa and pared good predictors? 1/0 Yes.
lrtest(olr.M1, olr.M0)
#Is the interaction significant? 1/2 No, can drop it.
lrtest(olr.M1, olr.M2)
#Is gpa important? 2/3 Hummm... slightly important, better to keep.
lrtest(olr.M2, olr.M3)
#Is pared important? 2/4 Yes! Keep it.
lrtest(olr.M2, olr.M4)
```

```{r}
olr.M2 <- polr(apply~pared+gpa, data=score) #Reduced model, without interaction.
olr.M5 <- olr.M2 #My final selection according to the above observations.

score <- score %>%
  cbind(., olr.M5.prob.=predict(olr.M5, ., type="probs")) %>% #estimated probability
  cbind(., olr.M5.decision=predict(olr.M5))                   #estimated result according to the probabilities
```

Goodness of fit: usually look for AIC, likelihood, and Residual Deviance.

```{r, results = 'hide'}
gf <- table(score$apply, score$olr.M5.decision)
accuracy <- (gf[1]+gf[5]+gf[9])/400

print(paste0("AIC = ", AIC(olr.M5), ".")) # The smaller the better
print(paste0("Log likelihood = ", logLik(olr.M5), ".")) # The larger the better
print(paste0("Overall accuracy = ", accuracy, ".")) # The larger the better

```

```{r, echo=F}
print(paste0("AIC = ", AIC(olr.M5), ".")) # The smaller the better
print(paste0("Log likelihood = ", logLik(olr.M5), ".")) # The larger the better
print(paste0("Overall accuracy = ", accuracy, ".")) # The larger the better

```
The values look nice. There are actually more more more statistis that we can use to access the goodness of fit for the OLR model. Here we demonstrated the most basic three. :) Now if we think the model is good enough, we can interpret the coefficient. 

```{r}
coef(summary(olr.M5)) # coefficients

```
- Example of interpretation (slope): For gpa, one unit increase in gpa, there is a 0.6 increase in the expected value of apply (in log odds scale), given that all of the other variables in the model are constant. A positive slope indicates a tendency for tahe response level to increase as the predictor increases.

- Example of interpretation (intercept): 2.17 is the expected log odds of being "unlikely" versus "somewhat likely" and "very likeli" combined when all the predictors are 0.

```{r}
exp(coef(olr.M5))     # proportional odds ratios
```
- Example of interpretation (proportional odds ratio): For one unit increase in gpa, the odds of moving from a lower categories to a high category is multiplied by 1.82.

Let's take a look how the fitted line looks like in our data.

```{r, echo=FALSE}
newdat <- data_frame(pared=as.factor(rep(0:1, 200)), gpa=rep(seq(from=1.9, to=4, length.out=100), 4)) %>%
  cbind(., yhat.prob=predict(olr.M5, ., type="probs")) %>%
  as_data_frame()
names(newdat) <- c("pared", "gpa", "unlikely", "somewhat likely", "very likely")
plot <- newdat %>%
  melt(id.vars=c("pared", "gpa")) %>%
  ggplot(aes(x=gpa, y=value, colour=variable)) +
    geom_line(size=1.5) +
    labs(y="Probability") +
    facet_grid(.~pared)
plot

```


